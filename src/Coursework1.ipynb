{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the necessary imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from Models.CustomClassifier import DecisionTree\n",
    "from Utilities.Evaluate import evaluate\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset, noisy_dataset = np.loadtxt(\"Data/wifi_db/clean_dataset.txt\", dtype = np.int32), np.loadtxt(\"Data/wifi_db/noisy_dataset.txt\", dtype = np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of Clean Dataset :  (2000, 8)\n",
      " Shape of Noisy Dataset :  (2000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\" Shape of Clean Dataset : \", clean_dataset.shape)\n",
    "print(\" Shape of Noisy Dataset : \", noisy_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decision_tree = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix:\n",
      " [[49  0  0  0]\n",
      " [ 0 47  2  0]\n",
      " [ 0  1 47  0]\n",
      " [ 0  0  0 49]]\n",
      "Average Accuracy: 0.9694999999999998\n",
      "Average Precision per Class: [0.9864439  0.96199557 0.94613786 0.98312653]\n",
      "Average Recall per Class: [0.98482256 0.95397633 0.9533359  0.98564694]\n",
      "Average F1 Score per Class: [0.98554796 0.95748653 0.94903621 0.98433554]\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross-Validation\n",
    "n_splits = 10\n",
    "np.random.shuffle(clean_dataset)\n",
    "n_samples = len(clean_dataset)\n",
    "fold_size = n_samples // n_splits\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "    # Variables to accumulate results\n",
    "total_cm = np.zeros((4, 4), dtype=int)  # Adjust for number of classes if needed\n",
    "total_accuracy = 0\n",
    "total_precision = np.zeros(4)  # Adjust for number of classes\n",
    "total_recall = np.zeros(4)     # Adjust for number of classes\n",
    "total_f1 = np.zeros(4)         # Adjust for number of classes\n",
    "\n",
    "for i in range(n_splits):\n",
    "    test_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "    train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]], axis = 0)\n",
    "\n",
    "        # Prepare training and testing data\n",
    "    train_set = clean_dataset[train_indices]\n",
    "    test_set = clean_dataset[test_indices]\n",
    "\n",
    "        # Train the decision tree\n",
    "    decision_tree.fit(train_set)\n",
    "       # Evaluate performance on the test fold\n",
    "    cm, precision, recall, accuracy, f1 = evaluate(test_set, decision_tree, 4)\n",
    "        \n",
    "        #print(cm)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Accumulate results\n",
    "    total_cm += cm\n",
    "    total_accuracy += accuracy\n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1 += f1\n",
    "\n",
    "    # Compute averages\n",
    "    \n",
    "average_cm = total_cm // n_splits\n",
    "average_accuracy = total_accuracy / n_splits\n",
    "average_precision = total_precision / n_splits\n",
    "average_recall = total_recall / n_splits\n",
    "average_f1 = total_f1 / n_splits\n",
    "\n",
    "    # Print the results\n",
    "print(\"Average Confusion Matrix:\\n\", average_cm)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Precision per Class:\", average_precision)\n",
    "print(\"Average Recall per Class:\", average_recall)\n",
    "print(\"Average F1 Score per Class:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
